{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Rolling DataFrame Window (Distributed)\"\n",
    "date: 2018-06-06\n",
    "type: technical_note\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awhile back, I found myself wanting to do some preprocessing for a sequence model using `pandas`. I was pretty pleased with [the solution that I came up with](https://napsterinblue.github.io/notes/python/pandas/rolling_df_window/). However, when I took the plunge and started tooling up in `PySpark`, it quickly occurred to me that my neat, `pandas.DataFrame.iloc` solution wasn't going to be making the transition with me.\n",
    "\n",
    "Unless of course, I was eager to `toPandas()` the whole thing right out of the gate, but that defeats the purpose of `PySpark`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same Data, Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of loading to `pandas`, we're going to read the csv into a `PySpark DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()\n",
    "\n",
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw = spark.read.csv('../data/moods.csv', header=True)\n",
    "# Let's ensure that it's sorted\n",
    "raw = raw.sort(['date', 'timestamp_id'])\n",
    "\n",
    "# We won't be using the date field after sorting\n",
    "data = raw.drop('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should look familiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|mood_id|timestamp_id|\n",
      "+-------+------------+\n",
      "|      3|           5|\n",
      "|      4|           1|\n",
      "|      4|           3|\n",
      "|      4|           5|\n",
      "|      4|           1|\n",
      "+-------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may recall, the idea here is that we scan through the `DataFrame`, `n` rows at a time, to create several consecutive *windows* that get collected into one big `numpy` array.\n",
    "\n",
    "I stashed away the output of the `pandas` implementation so we can check if we can arrive at the same results using `PySpark`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2662, 5, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "res = np.load('../data/res.pkl')\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterators, Man"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you think Spark, you should think Lazy Evaluation. And when you're thinking Lazy Evaluation and Python, iterators and the `itertools` library shouldn't be far behind.\n",
    "\n",
    "After rooting around in the `pyspark.sql.DataFrame` api, I stumbled across a `toLocalIterator()` method that might just prove useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it returns every record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2666"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(data.toLocalIterator()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And comparing the return value to the correct values shows that it also gives us our data in sorted order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  5.],\n",
       "       [ 4.,  1.],\n",
       "       [ 4.,  3.],\n",
       "       ..., \n",
       "       [ 4.,  4.],\n",
       "       [ 4.,  5.],\n",
       "       [ 4.,  1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(list(data.toLocalIterator()), dtype='float64')\n",
    "a[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  5.],\n",
       "       [ 4.,  1.],\n",
       "       [ 4.,  3.],\n",
       "       ..., \n",
       "       [ 4.,  4.],\n",
       "       [ 4.,  5.],\n",
       "       [ 4.,  1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([x[0] for x in res])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(a[:-4], b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I N T E R E S T I N G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Itertools Magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of my favorite functions in the `itertools` library is `islice`, which lazily serves up seqeuential values from an iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you squint hard enough, that's basically what we were doing in our `pandas` solution-- we'd look at the first 5 rows (here, start at `index=0` and end before `index=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(mood_id='3', timestamp_id='5'),\n",
       " Row(mood_id='4', timestamp_id='1'),\n",
       " Row(mood_id='4', timestamp_id='3'),\n",
       " Row(mood_id='4', timestamp_id='5'),\n",
       " Row(mood_id='4', timestamp_id='1')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(data.toLocalIterator(), 0, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'd shift the whole window down a step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(mood_id='4', timestamp_id='1'),\n",
       " Row(mood_id='4', timestamp_id='3'),\n",
       " Row(mood_id='4', timestamp_id='5'),\n",
       " Row(mood_id='4', timestamp_id='1'),\n",
       " Row(mood_id='5', timestamp_id='2')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(data.toLocalIterator(), 1, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we want to write a generator that will fire off an iterator at the `nth` index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _start_iterator_at_n(frame, n):\n",
    "    yield from islice(frame.toLocalIterator(), n, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a function that will make a `list` of these iterators of `size=windowSize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_window_iterator(frame, windowSize):\n",
    "    return [_start_iterator_at_n(frame, n) for n in range(windowSize)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling it is just instantiating the generators, pointed at some data with a `windowSize` in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "windowIterator = make_window_iterator(data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with `zip`, we can fire the iterators off simultaneously, and the whole process will end when the first one reaches the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2661, 5, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = []\n",
    "\n",
    "for window in zip(*windowIterator):\n",
    "    arr.append(window)\n",
    "    \n",
    "np.array(arr).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So close! Need to figure out how to get to those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Row(mood_id='3', timestamp_id='5'), Row(mood_id='4', timestamp_id='1'), Row(mood_id='4', timestamp_id='3'), Row(mood_id='4', timestamp_id='5'), Row(mood_id='4', timestamp_id='1'))\n",
      "(Row(mood_id='4', timestamp_id='1'), Row(mood_id='4', timestamp_id='3'), Row(mood_id='4', timestamp_id='5'), Row(mood_id='4', timestamp_id='1'), Row(mood_id='5', timestamp_id='2'))\n",
      "(Row(mood_id='4', timestamp_id='3'), Row(mood_id='4', timestamp_id='5'), Row(mood_id='4', timestamp_id='1'), Row(mood_id='5', timestamp_id='2'), Row(mood_id='3', timestamp_id='3'))\n",
      "(Row(mood_id='4', timestamp_id='5'), Row(mood_id='4', timestamp_id='1'), Row(mood_id='5', timestamp_id='2'), Row(mood_id='3', timestamp_id='3'), Row(mood_id='3', timestamp_id='4'))\n",
      "(Row(mood_id='4', timestamp_id='1'), Row(mood_id='5', timestamp_id='2'), Row(mood_id='3', timestamp_id='3'), Row(mood_id='3', timestamp_id='4'), Row(mood_id='3', timestamp_id='5'))\n"
     ]
    }
   ],
   "source": [
    "windowIterator = make_window_iterator(data, 5)\n",
    "\n",
    "for window in islice(zip(*windowIterator), 5):\n",
    "    print(window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some (dis)assembly Required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick up where we left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nextWindow = [x.__next__() for x in windowIterator]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got a window of 5 `Row` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(mood_id='5', timestamp_id='2'),\n",
       " Row(mood_id='3', timestamp_id='3'),\n",
       " Row(mood_id='3', timestamp_id='4'),\n",
       " Row(mood_id='3', timestamp_id='5'),\n",
       " Row(mood_id='1', timestamp_id='1')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nextWindow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the underlying data of a `Row` using `asDict()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(mood_id='5', timestamp_id='2')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nextWindow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mood_id': '5', 'timestamp_id': '2'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nextWindow[0].asDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And can, in turn, look at those values with a few more method calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['5', '2'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nextWindow[0].asDict().values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5', '2']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nextWindow[0].asDict().values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Closer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.,  2.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(nextWindow[0].asDict().values()), dtype='float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Closer**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 5.,  2.]),\n",
       " array([ 3.,  3.]),\n",
       " array([ 3.,  4.]),\n",
       " array([ 3.,  5.]),\n",
       " array([ 1.,  1.])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "([np.array(list(x.asDict().values()), dtype='float64') for x in nextWindow])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might figure this out yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  2.],\n",
       "       [ 3.,  3.],\n",
       "       [ 3.,  4.],\n",
       "       [ 3.,  5.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(([np.array(list(x.asDict().values()), dtype='float64') for x in nextWindow]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Presto!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...But that's crazy gross. Let's fix that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Assembly Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpack_row_vals(row):\n",
    "    return np.array(list(row.asDict().values()), dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_rows_to_np_matrix(window):\n",
    "    return np.array([unpack_row_vals(row) for row in window])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  2.],\n",
       "       [ 3.,  3.],\n",
       "       [ 3.,  4.],\n",
       "       [ 3.,  5.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rows_to_np_matrix(nextWindow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "windowIterator = make_window_iterator(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  5.]\n",
      " [ 4.  1.]\n",
      " [ 4.  3.]\n",
      " [ 4.  5.]\n",
      " [ 4.  1.]]\n",
      "[[ 4.  1.]\n",
      " [ 4.  3.]\n",
      " [ 4.  5.]\n",
      " [ 4.  1.]\n",
      " [ 5.  2.]]\n"
     ]
    }
   ],
   "source": [
    "arr = []\n",
    "\n",
    "for window in islice(zip(*windowIterator), 2):\n",
    "    print(df_rows_to_np_matrix(window))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we're on the right track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put together all of the pieces we've hammered out, and compare them against the correct `numpy` output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "windowIterator = make_window_iterator(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "\n",
    "for window in zip(*windowIterator):\n",
    "    arr.append(df_rows_to_np_matrix(window))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has the right shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2662, 5, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array(arr).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And has the right values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(res, np.array(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I figure out if this is even compatible with MLlib, lol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
