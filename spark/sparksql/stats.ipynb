{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Simple Stats Functions\"\n",
    "date: 2018-06-06\n",
    "type: technical_note\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first things I found myself missing after going from Pandas to PySpark was the ability to quickly hop in and get acclimated with my data.\n",
    "\n",
    "And while the suite of functionality doesn't perfectly carry over, it's worth noting that some of the more useful light-EDA methods have PySpark equivalents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisiting the dataset from SQL Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()\n",
    "\n",
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------+----------+--------------+--------------+\n",
      "|CallCharge|           DateTime|          Dest|    Origin|OriginatingNum|TerminatingNum|\n",
      "+----------+-------------------+--------------+----------+--------------+--------------+\n",
      "|       549|02/11/2016 01:51:41|    Birmingham|    London|     797308107|     797131221|\n",
      "|      2645|05/02/2016 01:26:54|        London|Manchester|     777121117|     777440392|\n",
      "|      1233|01/12/2016 21:12:54|    Manchester|  Victoria|     797009202|     784243404|\n",
      "|      2651|07/11/2016 01:07:34|      Victoria|Twickenham|     777557705|     798420467|\n",
      "|      3162|02/11/2016 22:22:26|      Scotland|     Leeds|     785434022|     779086250|\n",
      "|      2246|05/01/2016 20:12:35|Virginia Water|  Bradford|     779716202|     795137353|\n",
      "|       571|04/12/2016 23:53:52|         Ascot| Yorkshire|     775490102|     775019605|\n",
      "|      3291|06/11/2016 20:31:49|     Bracknell|Birmingham|     787581376|     797043387|\n",
      "|      2270|03/12/2016 12:15:17|      Bradford| Coventary|     789231956|     787649491|\n",
      "|      3420|06/02/2016 20:57:44|     Yorkshire|     Wales|     785969980|     789993090|\n",
      "+----------+-------------------+--------------+----------+--------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calls = spark.read.json('../data/callDetails.json')\n",
    "\n",
    "calls.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the get-go, we're probably interested in knowing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to know what *kind* of data we're looking at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CallCharge', 'bigint'),\n",
       " ('DateTime', 'string'),\n",
       " ('Dest', 'string'),\n",
       " ('Origin', 'string'),\n",
       " ('OriginatingNum', 'bigint'),\n",
       " ('TerminatingNum', 'bigint')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calls.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how each field is distributed.\n",
    "\n",
    "Notice that the `string` columns (thankfully) don't have a `mean` or `stddev`, but the `min/max`, amusingly, returns an alphabetical sort of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+---------+---------+-----------------+-----------------+\n",
      "|summary|        CallCharge|           DateTime|     Dest|   Origin|   OriginatingNum|   TerminatingNum|\n",
      "+-------+------------------+-------------------+---------+---------+-----------------+-----------------+\n",
      "|  count|               100|                100|      100|      100|              100|              100|\n",
      "|   mean|           1878.52|               null|     null|     null|   7.8435580264E8|   7.8687342871E8|\n",
      "| stddev|1091.9465010760011|               null|     null|     null|7903816.763526337|8173751.769309956|\n",
      "|    min|                 8|01/02/2016 03:07:33|    Ascot|    Ascot|        774188291|        774001818|\n",
      "|    max|              3596|09/12/2016 22:26:41|Yorkshire|Yorkshire|        799950372|        799779480|\n",
      "+-------+------------------+-------------------+---------+---------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calls.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `approxQuantile` function to get an even better idea of the dispersion of our data.\n",
    "\n",
    "However, because all of the data is distributed across several nodes, this is an *approximation*, as exhaustively sorting every record involves a good deal of shuffling. We can explore the trade-off between performance and accuracy by playing with the `relativeError` argument.\n",
    "\n",
    "We can also look for multiple different quantiles by passing floats between `0` and `1` to `probabilities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2551.0, 3405.0, 3596.0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calls.approxQuantile(col='CallCharge',\n",
    "                     probabilities=[.68, .95, .997],\n",
    "                     relativeError=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2385.0, 3596.0, 3596.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calls.approxQuantile(col='CallCharge',\n",
    "                     probabilities=[.68, .95, .997],\n",
    "                     relativeError=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3596.0, 3596.0, 3596.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calls.approxQuantile(col='CallCharge',\n",
    "                     probabilities=[.68, .95, .997],\n",
    "                     relativeError=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PySpark` doesn't have a handy \"correlate everything with everything\" function like `pandas` does-- that would be an absurd amount of shuffling.\n",
    "\n",
    "However, passing two attributes to `corr` is pretty performant and useful for spot-checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06796709282363027"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calls.corr('OriginatingNum', 'TerminatingNum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Tabulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll often look to `crosstab` when we're trying to figure out the co-incidence of different values in different features.\n",
    "\n",
    "I've scaled down the data here because as you can see, generating rows and columns for each pair quickly creates a huge sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+--------+---------+-----+------+----------+----------+--------+-----+---------+\n",
      "|   Dest_Origin|Birmingham|Bradford|Coventary|Leeds|London|Manchester|Twickenham|Victoria|Wales|Yorkshire|\n",
      "+--------------+----------+--------+---------+-----+------+----------+----------+--------+-----+---------+\n",
      "|        London|         0|       0|        0|    0|     0|         1|         0|       0|    0|        0|\n",
      "|     Bracknell|         1|       0|        0|    0|     0|         0|         0|       0|    0|        0|\n",
      "|      Victoria|         0|       0|        0|    0|     0|         0|         1|       0|    0|        0|\n",
      "|Virginia Water|         0|       1|        0|    0|     0|         0|         0|       0|    0|        0|\n",
      "|    Manchester|         0|       0|        0|    0|     0|         0|         0|       1|    0|        0|\n",
      "|      Scotland|         0|       0|        0|    1|     0|         0|         0|       0|    0|        0|\n",
      "|     Yorkshire|         0|       0|        0|    0|     0|         0|         0|       0|    1|        0|\n",
      "|    Birmingham|         0|       0|        0|    0|     1|         0|         0|       0|    0|        0|\n",
      "|         Ascot|         0|       0|        0|    0|     0|         0|         0|       0|    0|        1|\n",
      "|      Bradford|         0|       0|        1|    0|     0|         0|         0|       0|    0|        0|\n",
      "+--------------+----------+--------+---------+-----+------+----------+----------+--------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calls.limit(10).crosstab('Dest', 'Origin').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
