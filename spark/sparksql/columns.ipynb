{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Column Objects\"\n",
    "date: 2018-06-08\n",
    "type: technical_note\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned at the end of the [Anatomy of SparkSQL](https://napsterinblue.github.io/notes/spark/sparksql/overview/) notebook, working with `Column` objects in `SparkSQL` is tricky enough to merit its own discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we're going to use the Iris Dataset with a bunch of NULL values peppered in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession(sc)\n",
    "\n",
    "df = spark.read.csv('../data/somenulls.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---+---+----+\n",
      "|   a|   b|  c|  d|   e|\n",
      "+----+----+---+---+----+\n",
      "| 5.1| 3.5|1.4|0.2|null|\n",
      "| 4.9|   3|1.4|0.2|null|\n",
      "| 4.7|null|1.3|0.2|null|\n",
      "| 4.6| 3.1|1.5|0.2|   0|\n",
      "|null| 3.6|1.4|0.2|   0|\n",
      "+----+----+---+---+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting a `Column` from a `DataFrame` is just using `dict`-syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'a'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df['a']\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And stuffing that inside of a `DataFrame.select()` call, followed by some retrieval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|   a|\n",
      "+----+\n",
      "| 5.1|\n",
      "| 4.9|\n",
      "| 4.7|\n",
      "| 4.6|\n",
      "|null|\n",
      "+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(a).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also use the `col` function to make an instance of the `Column` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'a'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this breaks quietly if you provide a name that doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'nonsenseColumnName'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col('nonsenseColumnName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "until you go to pass it to the `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doesn't exist, friendo\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df.select(col('nonsenseColumnName'))\n",
    "except:\n",
    "    print(\"Doesn't exist, friendo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyhow, now we can do a few interesting things to modify our selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aliasing the name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe `a` isn't the most descriptive name we can come up with. The `alias` function is a pretty straight-forward fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'a AS `sepal_width`'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.alias('sepal_width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sepal_width|\n",
      "+-----------+\n",
      "|        5.1|\n",
      "|        4.9|\n",
      "|        4.7|\n",
      "|        4.6|\n",
      "|       null|\n",
      "+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(a.alias('sepal_width')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like `pandas.Series` operations, you can broadcast operations across the whole `Column` object. Like checking if a value is equal to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'(a = 0)'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|(a = 0)|\n",
      "+-------+\n",
      "|  false|\n",
      "|  false|\n",
      "|  false|\n",
      "|  false|\n",
      "|   null|\n",
      "+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(a == 0).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining this with `alias` makes for a neater-named column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|aIsZero|\n",
      "+-------+\n",
      "|  false|\n",
      "|  false|\n",
      "|  false|\n",
      "|  false|\n",
      "|   null|\n",
      "+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select((a == 0).alias('aIsZero')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, `a` is of type `string`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', 'string')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we were trying to scale the numbers by some arbitrary factor, `100`. Spark just figures out what to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|(a / 100)|\n",
      "+---------+\n",
      "|    0.051|\n",
      "|    0.049|\n",
      "|    0.047|\n",
      "|    0.046|\n",
      "|     null|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(a / 100).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BUT ASSUMING IT DIDN'T**, we could `cast` the column to an appropriate datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|(CAST(a AS FLOAT) / 100)|\n",
      "+------------------------+\n",
      "|    0.050999999046325684|\n",
      "|    0.049000000953674315|\n",
      "|     0.04699999809265137|\n",
      "|    0.045999999046325686|\n",
      "|                    null|\n",
      "+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "floatCol = a.cast(FloatType())\n",
    "\n",
    "df.select(floatCol / 100).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Nevermind the fact that this is a data-ingestion problem fixed by passing the `inferSchema=True` argument at the first read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First/Last `n` records are commonplace in data analysis. The syntax to do that is a bit tricky.\n",
    "\n",
    "But before I do anything, I'm going to drop all NULL records from our `DataFrame`, because the sort operation has no idea what to do about those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noNulls = df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+\n",
      "|  a|  b|  c|  d|  e|\n",
      "+---+---+---+---+---+\n",
      "|4.6|3.1|1.5|0.2|  0|\n",
      "|5.4|3.9|1.7|0.4|  0|\n",
      "|5.8|  4|1.2|0.2|  0|\n",
      "|5.4|3.9|1.3|0.4|  0|\n",
      "|5.7|3.8|1.7|0.3|  0|\n",
      "+---+---+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noNulls.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to use the `Column` function `asc` or `desc` on a particular column to dictate our sort order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sort_a_asc = noNulls['a'].asc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sort_a_desc = noNulls['a'].desc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which just returns a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sort_a_asc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we do a regular `DataFrame` select, with an `orderBy` call chained near the end, passing in our sorted column, and the table `Row`s adjust accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+\n",
      "|  a|  b|  c|  d|  e|\n",
      "+---+---+---+---+---+\n",
      "|4.4|  3|1.3|0.2|  0|\n",
      "|4.5|2.3|1.3|0.3|  0|\n",
      "|4.6|3.1|1.5|0.2|  0|\n",
      "|4.6|3.6|  1|0.2|  0|\n",
      "|4.7|3.2|1.6|0.2|  0|\n",
      "+---+---+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noNulls.orderBy(sort_a_asc).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+\n",
      "|  a|  b|  c|  d|  e|\n",
      "+---+---+---+---+---+\n",
      "|7.7|2.6|6.9|2.3|  2|\n",
      "|7.7|3.8|6.7|2.2|  2|\n",
      "|7.7|  3|6.1|2.3|  2|\n",
      "|7.4|2.8|6.1|1.9|  2|\n",
      "|7.3|2.9|6.3|1.8|  2|\n",
      "+---+---+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noNulls.orderBy(sort_a_desc).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also chain multiple sort conditions together by passing additional `Column`s to the `orderBy` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sort_b_desc = noNulls['b'].desc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the first 3 rows shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+\n",
      "|  a|  b|  c|  d|  e|\n",
      "+---+---+---+---+---+\n",
      "|7.7|2.6|6.9|2.3|  2|\n",
      "|7.7|3.8|6.7|2.2|  2|\n",
      "|7.7|  3|6.1|2.3|  2|\n",
      "|7.4|2.8|6.1|1.9|  2|\n",
      "|7.3|2.9|6.3|1.8|  2|\n",
      "+---+---+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noNulls.orderBy(sort_a_desc).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+\n",
      "|  a|  b|  c|  d|  e|\n",
      "+---+---+---+---+---+\n",
      "|7.7|3.8|6.7|2.2|  2|\n",
      "|7.7|  3|6.1|2.3|  2|\n",
      "|7.7|2.6|6.9|2.3|  2|\n",
      "|7.4|2.8|6.1|1.9|  2|\n",
      "|7.3|2.9|6.3|1.8|  2|\n",
      "+---+---+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noNulls.orderBy(sort_a_desc, sort_b_desc).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like above, we can broadcast boolean checks over our Columns to get a vector of True/False values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_sevenPointSeven = df['a'] == 7.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, however, that **this preserves NULLs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|   a|(a = 7.7)|\n",
      "+----+---------+\n",
      "| 5.1|    false|\n",
      "| 4.9|    false|\n",
      "| 4.7|    false|\n",
      "| 4.6|    false|\n",
      "|null|     null|\n",
      "+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('a', a_sevenPointSeven).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can `filter` down our `DataFrame` based on the `True/False` values of the `Column` we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(a_sevenPointSeven).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AND HOT DAMN** the `~` operator works here, too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(~a_sevenPointSeven).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get even fancier with the `between` statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_threeish = df['b'].between(2.8, 3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+\n",
      "|   b|((b >= 2.8) AND (b <= 3.2))|\n",
      "+----+---------------------------+\n",
      "| 3.5|                      false|\n",
      "|   3|                       true|\n",
      "|null|                       null|\n",
      "| 3.1|                       true|\n",
      "| 3.6|                      false|\n",
      "+----+---------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('b', b_threeish).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or just ridiculous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_secondDigit3 = (df['c'].cast('string').substr(3, 1) == '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------------------+\n",
      "|  c|(substring(CAST(c AS STRING), 3, 1) = 3)|\n",
      "+---+----------------------------------------+\n",
      "|1.4|                                   false|\n",
      "|1.4|                                   false|\n",
      "|1.3|                                    true|\n",
      "|1.5|                                   false|\n",
      "|1.4|                                   false|\n",
      "+---+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('c', c_secondDigit3).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works just like `pandas` :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+\n",
      "|  a|  b|  c|  d|  e|\n",
      "+---+---+---+---+---+\n",
      "|7.7|  3|6.1|2.3|  2|\n",
      "+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(b_threeish & a_sevenPointSeven).show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
