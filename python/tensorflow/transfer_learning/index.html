<!DOCTYPE html>
<html lang="en">

<head>

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66582-32"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-66582-32');
    </script>

    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta property="og:title" content="Transfer Learning" />
<meta property="og:description" content="Transfer learning is the act of using a pre-trained network as a way to give you a huge head start on training a neural network for whatever your current application is. There are a number of canonical networks floating around, all trained on significantly-better hardware than you or I readliy have on hand, furthermore, because so many of the earlier layers are so abstract, they&rsquo;re often useful for whatever purpose you&rsquo;re designing with, out of the box." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://napsterinblue.github.io/notes/python/tensorflow/transfer_learning/" />



<meta property="article:published_time" content="2018-10-06T00:00:00&#43;00:00"/>

<meta property="article:modified_time" content="2018-10-06T00:00:00&#43;00:00"/>











<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Transfer Learning"/>
<meta name="twitter:description" content="Transfer learning is the act of using a pre-trained network as a way to give you a huge head start on training a neural network for whatever your current application is. There are a number of canonical networks floating around, all trained on significantly-better hardware than you or I readliy have on hand, furthermore, because so many of the earlier layers are so abstract, they&rsquo;re often useful for whatever purpose you&rsquo;re designing with, out of the box."/>
<meta name="generator" content="Hugo 0.40.3" />

    
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "headline": "Transfer Learning",
  "url": "https://napsterinblue.github.io/notes/python/tensorflow/transfer_learning/",
  "wordCount": "1437",
  "datePublished": "2018-10-06T00:00:00&#43;00:00",
  "dateModified": "2018-10-06T00:00:00&#43;00:00",
  "author": {
    "@type": "Person",
    "name": ""
  }
}
</script> 

    <title>Transfer Learning</title>

    
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb"
        crossorigin="anonymous">

    
    <link href="https://napsterinblue.github.io/notes/css/custom.css" rel="stylesheet">
    <link href="https://napsterinblue.github.io/notes/css/syntax.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Muli:400,500,700" rel="stylesheet">

    <link href="" rel="alternate" type="application/rss+xml" title="Data Science Notes" />

    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>

</head>

<body>

    <nav class="navbar navbar-expand-sm fixed-top">
        <div class="container-fluid">
            <a class="navbar-brand" href="https://napsterinblue.github.io">Movies, Metrics, Musings</a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent"
                aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="nav navbar-nav mr-auto"></ul>
                <ul class="nav navbar-nav">
                    <li><a href="https://napsterinblue.github.io/pages/about.html" title="About">About</a></li>
                    <li><a href="https://napsterinblue.github.io/archives.html" title="Archive">Archive</a></li>
                    <li><a href="https://napsterinblue.github.io/pages/resources.html" title="Resources">Resources</a></li>
                    <li><a href="https://napsterinblue.github.io/notes/" title="Notes">My Notes</a></li>

                </ul>
            </div>
        </div>
    </nav>


    
    <div class="container">
        <div class="row">
            <div class="col-sm-12">

                 


<article>
  <div class="technical_note">
  <header>
    <h1 class="technical_note_title">Transfer Learning</h1>
    <div class="technical_note_date">
      <time datetime=" 2018-10-06T00:00:00Z "> 06 Oct 2018</time>
    </div>
  </header>
  <div class="content">
  

<p><em>Transfer learning</em> is the act of using a pre-trained network as a way to give you a huge head start on training a neural network for whatever your current application is. There are a number of canonical networks floating around, all trained on significantly-better hardware than you or I readliy have on hand, furthermore, because so many of the earlier layers are so abstract, they&rsquo;re often useful for whatever purpose you&rsquo;re designing with, out of the box.</p>

<h2 id="a-dataset">A Dataset</h2>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">%</span><span class="n">pylab</span> <span class="n">inline</span>

<span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="kn">import</span> <span class="n">cifar10</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span></code></pre></div>
<pre><code>Populating the interactive namespace from numpy and matplotlib


Using TensorFlow backend.
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="n">x_dev</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_dev</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=.</span><span class="mi">6</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=.</span><span class="mi">4</span><span class="p">)</span></code></pre></div>
<p>It&rsquo;s comprised of 60 thousand records.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_dev</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span></code></pre></div>
<pre><code>(50000, 4000, 6000)
</code></pre>

<p>Where each image is <code>32 x 32</code></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span></code></pre></div>
<pre><code>(32, 32, 3)
</code></pre>

<p>and an RGB image sampled from 10 different classes</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span></code></pre></div>
<pre><code>array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)
</code></pre>

<p>including</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">CLASSES</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;AIRPLANE&#39;</span><span class="p">,</span> <span class="s1">&#39;AUTOMOBILE&#39;</span><span class="p">,</span> <span class="s1">&#39;BIRD&#39;</span><span class="p">,</span> <span class="s1">&#39;CAT&#39;</span><span class="p">,</span> <span class="s1">&#39;DEER&#39;</span><span class="p">,</span>
           <span class="s1">&#39;DOG&#39;</span><span class="p">,</span> <span class="s1">&#39;FROG&#39;</span><span class="p">,</span> <span class="s1">&#39;HORSE&#39;</span><span class="p">,</span> <span class="s1">&#39;SHIP&#39;</span><span class="p">,</span> <span class="s1">&#39;TRUCK&#39;</span><span class="p">]</span></code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></code></pre></div>
<pre><code>&lt;matplotlib.image.AxesImage at 0x199e3ba8&gt;
</code></pre>

<p><img src="transfer_learning_13_1.png" alt="png" /></p>

<p>However, to predict in a multi-class fashion, we&rsquo;ll need to go from one column vector of integers</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span></code></pre></div>
<pre><code>(50000, 1)
</code></pre>

<p>To encoded representations of the same data</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_dev</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_dev</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span></code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span></code></pre></div>
<pre><code>(50000, 10)
</code></pre>

<h2 id="borrowing-vgg">Borrowing VGG</h2>

<p>For simplicity&rsquo;s sake, we&rsquo;re going to load <a href="https://napsterinblue.github.io/notes/machine_learning/computer_vision/vgg/">the VGG Architecture</a> for our transfer learning.</p>

<p>It was trained on <code>224x244</code> images, targeting 10 different classes. But because our image size is of a different resolution, we can&rsquo;t utilize the 3 hidden layers that come with VGG (hence the arguments below).</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">keras.applications.vgg16</span> <span class="kn">import</span> <span class="n">VGG16</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">VGG16</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">include_top</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></div>
<p>If we call <code>model.predict()</code> on one of our inputs, we obviously don&rsquo;t get back the multiclass prediction we&rsquo;re after.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">])</span><span class="o">.</span><span class="n">shape</span></code></pre></div>
<pre><code>(5, 1, 1, 512)
</code></pre>

<p>We want to reference the first and last layers for our next steps. Looking at the summary, we can see the names of each layer.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span></code></pre></div>
<pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 32, 32, 3)         0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
</code></pre>

<p>We&rsquo;ll use <code>model.get_layer()</code> to reference a layer by name, then <code>.output</code> to get its symbolic reference that we can use as an input later</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">input_layer</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="nb">input</span>
<span class="n">last_pooling_layer</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">output</span></code></pre></div>
<p>This allows us to tack on the typical Fully Connected layers that we see at the end of convolutional networks.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dense</span>

<span class="n">flatten</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">last_pooling_layer</span><span class="p">)</span>

<span class="n">fc1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="p">)(</span><span class="n">flatten</span><span class="p">)</span>
<span class="n">fc2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">fc1</span><span class="p">)</span>

<span class="n">output_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">fc2</span><span class="p">)</span></code></pre></div>
<p>All of the architecting out of the way, let&rsquo;s save this as its own object now, creating a new <code>Model</code> object and telling it where execution starts and ends.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>

<span class="n">custom_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">)</span></code></pre></div>
<p>If you look at a summary, you&rsquo;ll notice our 3 Fully Connected layers are now integrated.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">custom_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span></code></pre></div>
<pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 32, 32, 3)         0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 512)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 100)               51300     
_________________________________________________________________
dense_2 (Dense)              (None, 100)               10100     
_________________________________________________________________
dense_3 (Dense)              (None, 10)                1010      
=================================================================
Total params: 14,777,098
Trainable params: 14,777,098
Non-trainable params: 0
_________________________________________________________________
</code></pre>

<h3 id="training">Training</h3>

<p>We&rsquo;re likely pretty happy with all of the feature extraction layers, so we&rsquo;re not going to bother training them.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">custom_model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
    <span class="k">if</span> <span class="s1">&#39;dense&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="bp">False</span></code></pre></div>
<p>So all that remains for training are the Weights and Biases of of our last 3 layers.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">custom_model</span><span class="o">.</span><span class="n">trainable_weights</span></code></pre></div>
<pre><code>[&lt;tf.Variable 'dense_1/kernel:0' shape=(512, 100) dtype=float32_ref&gt;,
 &lt;tf.Variable 'dense_1/bias:0' shape=(100,) dtype=float32_ref&gt;,
 &lt;tf.Variable 'dense_2/kernel:0' shape=(100, 100) dtype=float32_ref&gt;,
 &lt;tf.Variable 'dense_2/bias:0' shape=(100,) dtype=float32_ref&gt;,
 &lt;tf.Variable 'dense_3/kernel:0' shape=(100, 10) dtype=float32_ref&gt;,
 &lt;tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32_ref&gt;]
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">custom_model</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span></code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">custom_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_dev</span><span class="p">,</span> <span class="n">y_dev</span><span class="p">),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span></code></pre></div>
<pre><code>Train on 50000 samples, validate on 4000 samples
Epoch 1/25
50000/50000 [==============================] - 32s 646us/step - loss: 1.8955 - acc: 0.4630 - val_loss: 1.3347 - val_acc: 0.5397
Epoch 2/25
50000/50000 [==============================] - 33s 656us/step - loss: 1.2259 - acc: 0.5744 - val_loss: 1.2499 - val_acc: 0.5780
Epoch 3/25
50000/50000 [==============================] - 31s 629us/step - loss: 1.1236 - acc: 0.6121 - val_loss: 1.2266 - val_acc: 0.5815
Epoch 4/25
50000/50000 [==============================] - 32s 641us/step - loss: 1.0603 - acc: 0.6337 - val_loss: 1.1724 - val_acc: 0.6012
Epoch 5/25
50000/50000 [==============================] - 31s 628us/step - loss: 1.0053 - acc: 0.6502 - val_loss: 1.1501 - val_acc: 0.6138
Epoch 6/25
50000/50000 [==============================] - 31s 628us/step - loss: 0.9580 - acc: 0.6668 - val_loss: 1.1921 - val_acc: 0.5975
Epoch 7/25
50000/50000 [==============================] - 32s 636us/step - loss: 0.9155 - acc: 0.6802 - val_loss: 1.1791 - val_acc: 0.6178
Epoch 8/25
50000/50000 [==============================] - 31s 620us/step - loss: 0.8741 - acc: 0.6945 - val_loss: 1.2193 - val_acc: 0.6160
Epoch 9/25
50000/50000 [==============================] - 31s 625us/step - loss: 0.8395 - acc: 0.7055 - val_loss: 1.2446 - val_acc: 0.6140
Epoch 10/25
50000/50000 [==============================] - 32s 640us/step - loss: 0.8053 - acc: 0.7183 - val_loss: 1.2829 - val_acc: 0.6062
Epoch 11/25
50000/50000 [==============================] - 34s 678us/step - loss: 0.7711 - acc: 0.7288 - val_loss: 1.3255 - val_acc: 0.5990
Epoch 12/25
50000/50000 [==============================] - 33s 651us/step - loss: 0.7439 - acc: 0.7373 - val_loss: 1.3539 - val_acc: 0.6000
Epoch 13/25
50000/50000 [==============================] - 31s 617us/step - loss: 0.7189 - acc: 0.7457 - val_loss: 1.4021 - val_acc: 0.6028
Epoch 14/25
50000/50000 [==============================] - 31s 616us/step - loss: 0.6947 - acc: 0.7545 - val_loss: 1.4472 - val_acc: 0.5970
Epoch 15/25
50000/50000 [==============================] - 31s 615us/step - loss: 0.6701 - acc: 0.7632 - val_loss: 1.4971 - val_acc: 0.5880
Epoch 16/25
50000/50000 [==============================] - 31s 616us/step - loss: 0.6518 - acc: 0.7682 - val_loss: 1.5427 - val_acc: 0.5930
Epoch 17/25
50000/50000 [==============================] - 31s 615us/step - loss: 0.6359 - acc: 0.7738 - val_loss: 1.5885 - val_acc: 0.5913
Epoch 18/25
50000/50000 [==============================] - 31s 615us/step - loss: 0.6161 - acc: 0.7806 - val_loss: 1.6323 - val_acc: 0.5873
Epoch 19/25
50000/50000 [==============================] - 31s 616us/step - loss: 0.6011 - acc: 0.7866 - val_loss: 1.6787 - val_acc: 0.5998
Epoch 20/25
50000/50000 [==============================] - 31s 614us/step - loss: 0.5828 - acc: 0.7934 - val_loss: 1.7442 - val_acc: 0.5857
Epoch 21/25
50000/50000 [==============================] - 31s 615us/step - loss: 0.5753 - acc: 0.7989 - val_loss: 1.7199 - val_acc: 0.5897
Epoch 22/25
50000/50000 [==============================] - 31s 628us/step - loss: 0.5600 - acc: 0.8026 - val_loss: 1.7905 - val_acc: 0.5935
Epoch 23/25
50000/50000 [==============================] - 31s 620us/step - loss: 0.5425 - acc: 0.8057 - val_loss: 1.8651 - val_acc: 0.5820
Epoch 24/25
50000/50000 [==============================] - 31s 616us/step - loss: 0.5361 - acc: 0.8101 - val_loss: 1.9242 - val_acc: 0.5863
Epoch 25/25
50000/50000 [==============================] - 30s 607us/step - loss: 0.5228 - acc: 0.8148 - val_loss: 1.9657 - val_acc: 0.5873





&lt;keras.callbacks.History at 0x1c314a90&gt;
</code></pre>

<p>Huzzah, it&rsquo;s only kind of crap!</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">custom_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span></code></pre></div>
<pre><code>6000/6000 [==============================] - 2s 356us/step





[2.0322601051330564, 0.5828333333333333]
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">test_idx</span> <span class="o">=</span> <span class="mi">1</span></code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">test_image</span> <span class="o">=</span> <span class="n">x_test</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">test_image</span><span class="p">)</span></code></pre></div>
<pre><code>&lt;matplotlib.image.AxesImage at 0x5316978&gt;
</code></pre>

<p><img src="transfer_learning_44_1.png" alt="png" /></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># tensorflow expects multiple records, thus</span>
<span class="c1"># a 4th dimension</span>
<span class="n">test_image</span> <span class="o">=</span> <span class="n">test_image</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span></code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">result</span> <span class="o">=</span> <span class="n">custom_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_image</span><span class="p">)</span></code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="s1">&#39;Prediction:&#39;</span><span class="p">,</span> <span class="n">CLASSES</span><span class="p">[</span><span class="n">result</span><span class="o">.</span><span class="n">argmax</span><span class="p">()])</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Actual:    &#39;</span><span class="p">,</span> <span class="n">CLASSES</span><span class="p">[</span><span class="n">y_test</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">()])</span></code></pre></div>
<pre><code>Prediction: TRUCK
Actual:     HORSE
</code></pre>

</div>
  <aside>
      <div class="bug_reporting">
          <h4>Find an error or bug?</h4>
          <p>Everything on this site is available on GitHub. Head to <a href='https://github.com/napsterinblue/notes/issues/new'>and submit a suggested change</a>. You can also message me directly on <a href='https://twitter.com/napsterinblue'>Twitter</a>.</p>
      </div>
      </aside>

    </div>
</article>




            </div>

        </div>
    </div>

    

    <footer class="footer text-center">
        <div class="container">
            <span class="text-muted">This project contains 113 pages and is available on <a href="https://github.com/napsterinblue/notes">GitHub</a>. Copyright &copy; NapsterInBlue, <time datetime="2018">2018</time>.</span>
        </div>
    </footer>

    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" integrity="sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh"
        crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" integrity="sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ"
        crossorigin="anonymous"></script>

</body>

</html>
