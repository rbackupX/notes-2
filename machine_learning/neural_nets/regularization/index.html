<!DOCTYPE html>
<html lang="en">

<head>

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66582-32"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-66582-32');
    </script>

    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta property="og:title" content="Bias, Variance, and Regularization" />
<meta property="og:description" content="I really like the way Andrew Ng describes bias and variance in Week 1 of Improving Deep Neural Networks.
%pylab inline from IPython.display import Image Image(&#39;images/bias_variance.PNG&#39;) Populating the interactive namespace from numpy and matplotlib  A model with high bias often looks linear and takes broad stroke approach to classification.
Whereas a model with high variance has complicated fitting behavior to its training set, and thus predicts poorly on new data." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://napsterinblue.github.io/notes/machine_learning/neural_nets/regularization/" />



<meta property="article:published_time" content="2018-08-20T00:00:00&#43;00:00"/>

<meta property="article:modified_time" content="2018-08-20T00:00:00&#43;00:00"/>











<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Bias, Variance, and Regularization"/>
<meta name="twitter:description" content="I really like the way Andrew Ng describes bias and variance in Week 1 of Improving Deep Neural Networks.
%pylab inline from IPython.display import Image Image(&#39;images/bias_variance.PNG&#39;) Populating the interactive namespace from numpy and matplotlib  A model with high bias often looks linear and takes broad stroke approach to classification.
Whereas a model with high variance has complicated fitting behavior to its training set, and thus predicts poorly on new data."/>
<meta name="generator" content="Hugo 0.40.3" />

    
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "headline": "Bias, Variance, and Regularization",
  "url": "https://napsterinblue.github.io/notes/machine_learning/neural_nets/regularization/",
  "wordCount": "470",
  "datePublished": "2018-08-20T00:00:00&#43;00:00",
  "dateModified": "2018-08-20T00:00:00&#43;00:00",
  "author": {
    "@type": "Person",
    "name": ""
  }
}
</script> 

    <title>Bias, Variance, and Regularization</title>

    
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb"
        crossorigin="anonymous">

    
    <link href="https://napsterinblue.github.io/notes/css/custom.css" rel="stylesheet">
    <link href="https://napsterinblue.github.io/notes/css/syntax.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Muli:400,500,700" rel="stylesheet">

    <link href="" rel="alternate" type="application/rss+xml" title="Data Science Notes" />

    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>

</head>

<body>

    <nav class="navbar navbar-expand-sm fixed-top">
        <div class="container-fluid">
            <a class="navbar-brand" href="https://napsterinblue.github.io">Movies, Metrics, Musings</a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent"
                aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="nav navbar-nav mr-auto"></ul>
                <ul class="nav navbar-nav">
                    <li><a href="https://napsterinblue.github.io/pages/about.html" title="About">About</a></li>
                    <li><a href="https://napsterinblue.github.io/archives.html" title="Archive">Archive</a></li>
                    <li><a href="https://napsterinblue.github.io/pages/resources.html" title="Resources">Resources</a></li>
                    <li><a href="https://napsterinblue.github.io/notes/" title="Notes">My Notes</a></li>

                </ul>
            </div>
        </div>
    </nav>


    
    <div class="container">
        <div class="row">
            <div class="col-sm-12">

                 


<article>
  <div class="technical_note">
  <header>
    <h1 class="technical_note_title">Bias, Variance, and Regularization</h1>
    <div class="technical_note_date">
      <time datetime=" 2018-08-20T00:00:00Z "> 20 Aug 2018</time>
    </div>
  </header>
  <div class="content">
  

<p>I really like the way Andrew Ng describes bias and variance in Week 1 of <em>Improving Deep Neural Networks</em>.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">%</span><span class="n">pylab</span> <span class="n">inline</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="n">Image</span><span class="p">(</span><span class="s1">&#39;images/bias_variance.PNG&#39;</span><span class="p">)</span></code></pre></div>
<pre><code>Populating the interactive namespace from numpy and matplotlib
</code></pre>

<p><img src="regularization_2_1.png" alt="png" /></p>

<p>A model with high bias often looks linear and takes broad stroke approach to classification.</p>

<p>Whereas a model with high variance has complicated fitting behavior to its training set, <em>and thus predicts poorly on new data</em>.</p>

<h3 id="train-vs-test-set-error">Train vs Test Set Error</h3>

<p>Or described using a simple example&ndash; say you were trying to build a classifier to automate something you could <em>manually</em> do with an extremely-low error rate</p>

<p><center><table>
<thead><tr><td>Train Set Error</td><td>Dev Set Error</td><td>Outcome</td></tr></thead>
<tr><td>1%</td><td>11%</td><td>High Variance</td></tr>
<tr><td>15%</td><td>16%</td><td>High Bias</td></tr>
<tr><td>15%</td><td>30%</td><td>High Bias, High Variance</td></tr>
<tr><td>1%</td><td>1%</td><td>Low Bias, Low Variance</td></tr>
</table></center></p>

<p>So there are things that we can do to help stabilize these errors.</p>

<p>If you have a model with high bias, you might consider a more robust network or training longer. The meat of this notebook is in addressing high variance.</p>

<h2 id="correction-schemes-for-high-variance">Correction Schemes for High Variance</h2>

<p>You have a model that has learned too niche/nuacned of features. And so you want to figure out some sort of penalizing scheme to keep your model from getting too excited about any one feature.</p>

<h3 id="l2-normalization">L2 Normalization</h3>

<p>L2 Normalization gives us a concept of distance or magnitude. The idea being that if any one feature is too &ldquo;big&rdquo; then you proportionally penalize your model.</p>

<p>In the same manner that the distance between two points can be expressed as</p>

<p>$\sqrt{(y_2 - y_1)^2 + (x_2 - x_1)^2}$</p>

<p>We can extend that same idea to a matrix via the following</p>

<p>$ \sqrt{\sum_{i=1}^{n} w_i^{2}}$</p>

<p>Which is available to us via a call to the convenient <code>numpy.linalg.norm()</code></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code></pre></div>
<pre><code>3.0366626116644495
</code></pre>

<p>In the context of a Neural Network, this means that our new cost function becomes</p>

<p>$J(W^{[1]}, b^{[1]}, &hellip;, W^{[l]}, b^{[l]}) = \frac{1}{m} \sum \mathcal{L}\big(\hat{y}^{i}, y^i\big) + \frac{\lambda}{2m} \sum_{l}\sum_j\sum_k||W_j^{l}||_k^{2}$</p>

<p>However, you should place great care in what value you put for this <code>lambda</code> parameter. Too large, and you will penalize everything and make all of your networks basically linear&ndash; defeating the purpose of using non-linear activation functions.</p>

<p>On the other hand, too low and you&rsquo;re just adding more computation for little error correction.</p>

<h3 id="dropout-regularization">Dropout Regularization</h3>

<p>Dropout regularization achieves a similar result, but through different means.</p>

<p>Instead of adjusting each weight via a constant, in dropout, we just deactivate nodes (with some random probability) during the forward and back propagation step of one cycle. Then we reactivate them and deactivate other nodes with the same random probability. This ensures that we don&rsquo;t ever over-rely on any one node to learn features, thus don&rsquo;t overfit.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">Image</span><span class="p">(</span><span class="s1">&#39;images/dropout.PNG&#39;</span><span class="p">)</span></code></pre></div>
<p><img src="regularization_22_0.png" alt="png" /></p>

<p>Couple notes on this, though:</p>

<ul>
<li>We don&rsquo;t do any sort of dropout when using the model to predict</li>
<li>This completely muddies the monotonically-decreasing performance of Gradient Descent, so you lose that as a debugging tool</li>
</ul>

</div>
  <aside>
      <div class="bug_reporting">
          <h4>Find an error or bug?</h4>
          <p>Everything on this site is available on GitHub. Head to <a href='https://github.com/napsterinblue/notes/issues/new'>and submit a suggested change</a>. You can also message me directly on <a href='https://twitter.com/napsterinblue'>Twitter</a>.</p>
      </div>
      </aside>

    </div>
</article>




            </div>

        </div>
    </div>

    

    <footer class="footer text-center">
        <div class="container">
            <span class="text-muted">This project contains 113 pages and is available on <a href="https://github.com/napsterinblue/notes">GitHub</a>. Copyright &copy; NapsterInBlue, <time datetime="2018">2018</time>.</span>
        </div>
    </footer>

    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" integrity="sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh"
        crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" integrity="sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ"
        crossorigin="anonymous"></script>

</body>

</html>
